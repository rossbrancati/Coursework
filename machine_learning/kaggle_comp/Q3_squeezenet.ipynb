{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"markdown","source":"**Part 1: Preprocess data**","metadata":{}},{"cell_type":"markdown","source":"Load packages","metadata":{}},{"cell_type":"code","source":"#load in packages\nimport os\nimport numpy as np\nimport pandas as pd\nimport cv2\nfrom sklearn.model_selection import train_test_split\nimport tensorflow as tf\nfrom tensorflow import keras\nfrom tensorflow.keras import layers\nfrom tensorflow.keras.regularizers import l2\nfrom tensorflow.keras.preprocessing.image import ImageDataGenerator\nfrom tensorflow.python.client import device_lib\nimport seaborn as sns\nimport matplotlib.pyplot as plt","metadata":{"execution":{"iopub.status.busy":"2021-12-06T22:18:39.789516Z","iopub.execute_input":"2021-12-06T22:18:39.789833Z","iopub.status.idle":"2021-12-06T22:18:45.712481Z","shell.execute_reply.started":"2021-12-06T22:18:39.789741Z","shell.execute_reply":"2021-12-06T22:18:45.711801Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"#Check to see which devices are availible for running network on\ntf.config.get_visible_devices()","metadata":{"execution":{"iopub.status.busy":"2021-12-06T22:19:03.439997Z","iopub.execute_input":"2021-12-06T22:19:03.440471Z","iopub.status.idle":"2021-12-06T22:19:03.631984Z","shell.execute_reply.started":"2021-12-06T22:19:03.440432Z","shell.execute_reply":"2021-12-06T22:19:03.631152Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"#check if GPU available to use\n#The GPU in the Kaggle online \nif 'GPU' in str(device_lib.list_local_devices()):\n    config = tf.compat.v1.ConfigProto(device_count = {'GPU': 0})\n    sess = tf.compat.v1.Session(config=config) ","metadata":{"execution":{"iopub.status.busy":"2021-12-06T22:19:07.194314Z","iopub.execute_input":"2021-12-06T22:19:07.194573Z","iopub.status.idle":"2021-12-06T22:19:09.105894Z","shell.execute_reply.started":"2021-12-06T22:19:07.194545Z","shell.execute_reply":"2021-12-06T22:19:09.104273Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"Kaggle has online GPUs that can be used, but they are time limited. Before running the notebook, turn the GPU on in the GUI on the right side of the notebook. ","metadata":{}},{"cell_type":"markdown","source":"**Part 2: Get the data**","metadata":{}},{"cell_type":"code","source":"#read training data and drop the meta data\ntrain = pd.read_csv('../input/petfinder-pawpularity-score/train.csv')\ntrain = train.drop(['Subject Focus', 'Eyes', 'Face', 'Near', 'Action', 'Accessory', 'Group', 'Collage', 'Human', 'Occlusion', 'Info', 'Blur'],axis=1)\n\ntest = pd.read_csv('../input/petfinder-pawpularity-score/test.csv')\ntest = test.drop(['Subject Focus', 'Eyes', 'Face', 'Near', 'Action', 'Accessory', 'Group', 'Collage', 'Human', 'Occlusion', 'Info', 'Blur'],axis=1)","metadata":{"execution":{"iopub.status.busy":"2021-12-06T22:19:10.967314Z","iopub.execute_input":"2021-12-06T22:19:10.967587Z","iopub.status.idle":"2021-12-06T22:19:11.021301Z","shell.execute_reply.started":"2021-12-06T22:19:10.967557Z","shell.execute_reply":"2021-12-06T22:19:11.020569Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"#quick view of training data\ntrain","metadata":{"execution":{"iopub.status.busy":"2021-12-06T22:19:15.499304Z","iopub.execute_input":"2021-12-06T22:19:15.499554Z","iopub.status.idle":"2021-12-06T22:19:15.516107Z","shell.execute_reply.started":"2021-12-06T22:19:15.499526Z","shell.execute_reply":"2021-12-06T22:19:15.515421Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"#functions to add image paths to data frames for easy loading of images\ndef train_id_to_path(x):\n    return '../input/petfinder-pawpularity-score/train/' + x + \".jpg\"\ndef test_id_to_path(x):\n    return '../input/petfinder-pawpularity-score/test/' + x + \".jpg\"","metadata":{"execution":{"iopub.status.busy":"2021-12-06T22:19:17.952226Z","iopub.execute_input":"2021-12-06T22:19:17.952472Z","iopub.status.idle":"2021-12-06T22:19:17.95731Z","shell.execute_reply.started":"2021-12-06T22:19:17.952446Z","shell.execute_reply":"2021-12-06T22:19:17.956621Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"#also need to add .jpg extensions to image paths\ntrain[\"img_path\"] = train[\"Id\"].apply(train_id_to_path)\ntest[\"img_path\"] = test[\"Id\"].apply(test_id_to_path)","metadata":{"execution":{"iopub.status.busy":"2021-12-06T22:19:21.284212Z","iopub.execute_input":"2021-12-06T22:19:21.284604Z","iopub.status.idle":"2021-12-06T22:19:21.29803Z","shell.execute_reply.started":"2021-12-06T22:19:21.284569Z","shell.execute_reply":"2021-12-06T22:19:21.297245Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"#quick view of training data with image paths included\ntrain","metadata":{"execution":{"iopub.status.busy":"2021-12-06T22:19:24.139976Z","iopub.execute_input":"2021-12-06T22:19:24.140231Z","iopub.status.idle":"2021-12-06T22:19:24.153397Z","shell.execute_reply.started":"2021-12-06T22:19:24.140203Z","shell.execute_reply":"2021-12-06T22:19:24.152606Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"**Part 3: Pre-processing image data**","metadata":{}},{"cell_type":"code","source":"#Set the size image you want to use\nimage_height = 128\nimage_width = 128\n\n#Function that generates tensor\ndef generate_tensor(image_path):\n    raw = tf.io.read_file(image_path)\n    image = tf.image.decode_jpeg(raw, channels=3)\n    image = tf.cast(image, tf.float32) / 255.0\n    image = tf.image.resize(image, (image_height, image_width))\n    return image","metadata":{"execution":{"iopub.status.busy":"2021-12-06T22:19:27.259185Z","iopub.execute_input":"2021-12-06T22:19:27.259449Z","iopub.status.idle":"2021-12-06T22:19:27.265011Z","shell.execute_reply.started":"2021-12-06T22:19:27.25942Z","shell.execute_reply":"2021-12-06T22:19:27.26421Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"#get all the images in the training folder and put their tensors in a list\nX = []\nfor img in train['img_path']:\n    new_img_tensor = generate_tensor(img)\n    X.append(new_img_tensor)","metadata":{"execution":{"iopub.status.busy":"2021-12-06T22:19:29.715839Z","iopub.execute_input":"2021-12-06T22:19:29.716547Z","iopub.status.idle":"2021-12-06T22:20:53.66195Z","shell.execute_reply.started":"2021-12-06T22:19:29.716511Z","shell.execute_reply":"2021-12-06T22:20:53.661179Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"#same for the test images\nX_submission = []\nfor img in test['img_path']:\n    new_img_tensor = generate_tensor(img)\n    X_submission.append(new_img_tensor)","metadata":{"execution":{"iopub.status.busy":"2021-12-06T22:21:56.554237Z","iopub.execute_input":"2021-12-06T22:21:56.554811Z","iopub.status.idle":"2021-12-06T22:21:56.612809Z","shell.execute_reply.started":"2021-12-06T22:21:56.554754Z","shell.execute_reply":"2021-12-06T22:21:56.612071Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"#convert X to array\nX = np.array(X)","metadata":{"execution":{"iopub.status.busy":"2021-12-06T22:22:00.457323Z","iopub.execute_input":"2021-12-06T22:22:00.457588Z","iopub.status.idle":"2021-12-06T22:22:03.764805Z","shell.execute_reply.started":"2021-12-06T22:22:00.457558Z","shell.execute_reply":"2021-12-06T22:22:03.764037Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"#convert X_submission to array\nX_submission = np.array(X_submission)","metadata":{"execution":{"iopub.status.busy":"2021-12-06T22:22:05.322357Z","iopub.execute_input":"2021-12-06T22:22:05.322906Z","iopub.status.idle":"2021-12-06T22:22:05.329406Z","shell.execute_reply.started":"2021-12-06T22:22:05.322865Z","shell.execute_reply":"2021-12-06T22:22:05.328636Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"Now that all of our data is pre-processed and in tensor form, we can build the model","metadata":{}},{"cell_type":"markdown","source":"**Part 3: split data into train and test**","metadata":{}},{"cell_type":"code","source":"#generate training data\ny = train['Pawpularity']","metadata":{"execution":{"iopub.status.busy":"2021-12-06T22:22:13.748533Z","iopub.execute_input":"2021-12-06T22:22:13.748843Z","iopub.status.idle":"2021-12-06T22:22:13.753116Z","shell.execute_reply.started":"2021-12-06T22:22:13.748806Z","shell.execute_reply":"2021-12-06T22:22:13.752406Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"#split into training and testing data using a 90-10 split\nx_train, x_test, y_train, y_test = train_test_split(X, y, test_size=0.1, random_state=7)","metadata":{"execution":{"iopub.status.busy":"2021-12-06T22:22:17.268108Z","iopub.execute_input":"2021-12-06T22:22:17.26876Z","iopub.status.idle":"2021-12-06T22:22:17.806174Z","shell.execute_reply.started":"2021-12-06T22:22:17.268721Z","shell.execute_reply":"2021-12-06T22:22:17.805335Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"x_train.shape","metadata":{"execution":{"iopub.status.busy":"2021-12-06T22:22:20.469492Z","iopub.execute_input":"2021-12-06T22:22:20.469972Z","iopub.status.idle":"2021-12-06T22:22:20.47725Z","shell.execute_reply.started":"2021-12-06T22:22:20.469934Z","shell.execute_reply":"2021-12-06T22:22:20.476612Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"**Part 4: Define the model layers.**\n\nThis is a SqueezeNet, which achieved the same accuracy as AlexNet, but is much smaller (reference: https://arxiv.org/pdf/1602.07360.pdf)","metadata":{}},{"cell_type":"markdown","source":"A fire module is a building block for CNN archetecture of the SqueezeNet which feeds 1x1 convolutional layers into an expanded layer with 1x1 and 3x3 convolutional layers","metadata":{}},{"cell_type":"code","source":"#define the fire_module\ndef fire_module(x,s1,e1,e3):\n    s1x = tf.keras.layers.Conv2D(s1,kernel_size = 1, padding = 'same')(x)\n    s1x = tf.keras.layers.ReLU()(s1x)\n    e1x = tf.keras.layers.Conv2D(e1,kernel_size = 1, padding = 'same')(s1x)\n    e3x = tf.keras.layers.Conv2D(e3,kernel_size = 3, padding = 'same')(s1x)\n    x = tf.keras.layers.concatenate([e1x,e3x])\n    x = tf.keras.layers.ReLU()(x)\n    return x","metadata":{"execution":{"iopub.status.busy":"2021-12-06T22:22:24.8467Z","iopub.execute_input":"2021-12-06T22:22:24.847001Z","iopub.status.idle":"2021-12-06T22:22:24.853425Z","shell.execute_reply.started":"2021-12-06T22:22:24.846971Z","shell.execute_reply":"2021-12-06T22:22:24.85274Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"#model layers\ninputs = tf.keras.Input(shape=(image_height,image_width,3))\nx = inputs\nnclasses=1\nx = tf.keras.layers.Conv2D(96,kernel_size=(7,7),strides=(2,2),padding='same')(x)\nx = tf.keras.layers.MaxPool2D(pool_size=(3,3), strides = (2,2))(x)\nx = fire_module(x, s1 = 16, e1 = 64, e3 = 64) #2\nx = fire_module(x, s1 = 16, e1 = 64, e3 = 64) #3\nx = fire_module(x, s1 = 32, e1 = 128, e3 = 128) #4\nx = tf.keras.layers.MaxPool2D(pool_size=(3,3), strides = (2,2))(x)\nx = fire_module(x, s1 = 32, e1 = 128, e3 = 128) #5\nx = fire_module(x, s1 = 48, e1 = 192, e3 = 192) #6\nx = fire_module(x, s1 = 48, e1 = 192, e3 = 192) #7\nx = fire_module(x, s1 = 64, e1 = 256, e3 = 256) #8\nx = tf.keras.layers.MaxPool2D(pool_size=(3,3), strides = (2,2))(x)\nx = fire_module(x, s1 = 64, e1 = 256, e3 = 256) #9\nx = tf.keras.layers.Dropout(0.5)(x)\nx = tf.keras.layers.Conv2D(nclasses,kernel_size = 1)(x)\noutput = tf.keras.layers.AveragePooling2D(pool_size=(7,7))(x)\nmodel = tf.keras.Model(inputs, output)\n","metadata":{"execution":{"iopub.status.busy":"2021-12-06T22:22:27.972596Z","iopub.execute_input":"2021-12-06T22:22:27.973117Z","iopub.status.idle":"2021-12-06T22:22:28.252421Z","shell.execute_reply.started":"2021-12-06T22:22:27.973077Z","shell.execute_reply":"2021-12-06T22:22:28.251692Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"#compile the model \nmodel.compile(loss = 'mse', optimizer = 'Adam', metrics = [tf.keras.metrics.RootMeanSquaredError(name=\"rmse\"), \"mae\", \"mape\"])","metadata":{"execution":{"iopub.status.busy":"2021-12-06T22:22:31.354716Z","iopub.execute_input":"2021-12-06T22:22:31.355256Z","iopub.status.idle":"2021-12-06T22:22:31.37301Z","shell.execute_reply.started":"2021-12-06T22:22:31.35522Z","shell.execute_reply":"2021-12-06T22:22:31.372305Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"**Part 5: Fit the model with the training data**","metadata":{}},{"cell_type":"markdown","source":"This trick came from a tutorial which will help with randomness of orientation, zoom, and size shifts of images because not all images in the training set are oriented the same way (source: https://www.kaggle.com/alexteboul/tutorial-part-3-cnn-image-modeling-1)","metadata":{}},{"cell_type":"code","source":"#augment data\ndata_augmentation = ImageDataGenerator(\n    rotation_range = 15, \n    zoom_range = 0.15,\n    width_shift_range = 0.2, \n    height_shift_range = 0.2, \n    shear_range = 0.1,\n    horizontal_flip = True, \n    fill_mode = \"nearest\")","metadata":{"execution":{"iopub.status.busy":"2021-12-06T22:22:33.977407Z","iopub.execute_input":"2021-12-06T22:22:33.977666Z","iopub.status.idle":"2021-12-06T22:22:33.982534Z","shell.execute_reply.started":"2021-12-06T22:22:33.977639Z","shell.execute_reply":"2021-12-06T22:22:33.981791Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"Fit the model using training data","metadata":{}},{"cell_type":"code","source":"#fit the model with training data\nhistory = model.fit(\n    data_augmentation.flow(x_train,y_train,batch_size=32),\n    validation_data = (x_test,y_test),\n    steps_per_epoch = len(x_train) // 32,\n    epochs = 50\n)","metadata":{"execution":{"iopub.status.busy":"2021-12-06T22:24:03.50047Z","iopub.execute_input":"2021-12-06T22:24:03.500727Z","iopub.status.idle":"2021-12-06T22:55:27.406967Z","shell.execute_reply.started":"2021-12-06T22:24:03.500698Z","shell.execute_reply":"2021-12-06T22:55:27.40617Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"**Part 6: Generate Predictions on Test Set**","metadata":{}},{"cell_type":"code","source":"#predict on submission\ny_pred = model.predict(X_submission)","metadata":{"execution":{"iopub.status.busy":"2021-12-06T22:55:42.018181Z","iopub.execute_input":"2021-12-06T22:55:42.018432Z","iopub.status.idle":"2021-12-06T22:55:42.361637Z","shell.execute_reply.started":"2021-12-06T22:55:42.018403Z","shell.execute_reply":"2021-12-06T22:55:42.36091Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"#reshape y_pred\ny_pred = y_pred.reshape(8,1)","metadata":{"execution":{"iopub.status.busy":"2021-12-06T22:55:57.502966Z","iopub.execute_input":"2021-12-06T22:55:57.503502Z","iopub.status.idle":"2021-12-06T22:55:57.507433Z","shell.execute_reply.started":"2021-12-06T22:55:57.503464Z","shell.execute_reply":"2021-12-06T22:55:57.506511Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"#convert to dataframe \ny_pred_df = pd.DataFrame()\ny_pred_df['Id'] = test['Id']\ny_pred_df['Pawpularity'] = y_pred","metadata":{"execution":{"iopub.status.busy":"2021-12-06T22:56:00.944666Z","iopub.execute_input":"2021-12-06T22:56:00.94523Z","iopub.status.idle":"2021-12-06T22:56:00.951157Z","shell.execute_reply.started":"2021-12-06T22:56:00.945191Z","shell.execute_reply":"2021-12-06T22:56:00.95045Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"#submit to csv\ny_pred_df.to_csv('submission.csv',index=False)","metadata":{"execution":{"iopub.status.busy":"2021-12-06T22:56:06.646421Z","iopub.execute_input":"2021-12-06T22:56:06.647148Z","iopub.status.idle":"2021-12-06T22:56:06.653519Z","shell.execute_reply.started":"2021-12-06T22:56:06.647105Z","shell.execute_reply":"2021-12-06T22:56:06.652831Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"#plot the training and validation RMSE for each epoch\nplt.figure()\nplt.plot(history.history[\"rmse\"], label=\"Train RMSE\")\nplt.plot(history.history[\"val_rmse\"], label=\"Validation RMSE\")\nplt.xlabel(\"Epoch #\")\nplt.ylabel(\"RMSE\")\nplt.title(\"RMSE for each Epoch\")\nplt.legend(loc=\"upper right\")","metadata":{"execution":{"iopub.status.busy":"2021-12-06T22:56:15.010702Z","iopub.execute_input":"2021-12-06T22:56:15.01125Z","iopub.status.idle":"2021-12-06T22:56:15.246726Z","shell.execute_reply.started":"2021-12-06T22:56:15.011212Z","shell.execute_reply":"2021-12-06T22:56:15.246084Z"},"collapsed":true,"jupyter":{"outputs_hidden":true},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"#plot the training and validation RMSE for each epoch\nplt.figure()\nplt.plot(history.history[\"loss\"])\nplt.xlabel(\"Epoch #\")\nplt.ylabel(\"Loss\")\nplt.title(\"Loss for each Epoch\")","metadata":{"execution":{"iopub.status.busy":"2021-12-06T22:56:23.185904Z","iopub.execute_input":"2021-12-06T22:56:23.18831Z","iopub.status.idle":"2021-12-06T22:56:23.419759Z","shell.execute_reply.started":"2021-12-06T22:56:23.188256Z","shell.execute_reply":"2021-12-06T22:56:23.419117Z"},"collapsed":true,"jupyter":{"outputs_hidden":true},"trusted":true},"execution_count":null,"outputs":[]}]}